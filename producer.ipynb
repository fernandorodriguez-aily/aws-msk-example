{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:15:04.049418Z",
     "start_time": "2024-06-10T12:14:53.734284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from confluent_kafka import Producer\n",
    "from aily_py_commons.io.env_vars import (\n",
    "    INFRASTRUCTURE_PROD,\n",
    "    AilySettings,\n",
    ")\n",
    "from aily_data_aws.aws.secrets import get_secret"
   ],
   "id": "71a5fec7c25abbcd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:15:05.222836Z",
     "start_time": "2024-06-10T12:15:04.052006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AilySettings(INFRASTRUCTURE_PROD)\n",
    "\n",
    "secret_name = \"aily/infrastructure/dev/msk/msk-controlplane-infrastructure-dev/ailypubsub\"\n",
    "\n",
    "secret = get_secret(secret_name)\n",
    "\n",
    "# Producer configuration using AWS secrets\n",
    "producer_conf = {\n",
    "    'bootstrap.servers': secret[\"bootstrap_public\"],\n",
    "    'security.protocol': \"SASL_SSL\",\n",
    "    'sasl.mechanism': \"SCRAM-SHA-512\",\n",
    "    'sasl.username': secret[\"username\"],\n",
    "    'sasl.password': secret[\"password\"]\n",
    "}\n",
    "\n",
    "producer = Producer(**producer_conf)"
   ],
   "id": "e3d1243d6231013d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33m2024-06-10 14:15:04 CEST+0200 - WARNING - aily-logging:\u001B[0m \u001B[37mYou are using a dictionary to configure AilySettings. This is not recommended.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:15:05.658760Z",
     "start_time": "2024-06-10T12:15:05.223657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f'Message delivery failed: {err}')\n",
    "    else:\n",
    "        print(f'Message delivered to {msg.topic()} [{msg.partition()}]')"
   ],
   "id": "9d5049126dfc0027",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message delivered to langfuse-aggregator [5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Send string message",
   "id": "5c5e7f8b32836200"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:15:06.631520Z",
     "start_time": "2024-06-10T12:15:05.660622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message = 'Hello, Kafka!'\n",
    "producer.produce('kafka-message-test', message.encode('utf-8'), callback=delivery_report)\n",
    "\n",
    "# Wait for any outstanding messages to be delivered and delivery reports to be received\n",
    "producer.flush()"
   ],
   "id": "2f4fcef937f31068",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message delivered to kafka-message-test [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Send JSON mesage\n",
    "\n",
    "We are going to send data from a simple dataframe"
   ],
   "id": "e07bd56397fb0d6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:15:39.476666Z",
     "start_time": "2024-06-10T12:15:39.393124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame({\n",
    "    'column1': [1, 2, 3],\n",
    "    'column2': ['a', 'b', 'c']\n",
    "})\n",
    "\n",
    "# Convert DataFrame to dictionary\n",
    "data_dict = df.to_dict(orient='records')  # List of dictionaries, one per row\n",
    "\n",
    "# Serialize dictionary to JSON\n",
    "message = json.dumps(data_dict)\n",
    "\n",
    "producer.produce('kafka-message-test', message.encode('utf-8'), callback=delivery_report)\n",
    "\n",
    "# Wait for any outstanding messages to be delivered and delivery reports to be received\n",
    "producer.flush()"
   ],
   "id": "3a95ccf54a2ebcac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message delivered to kafka-message-test [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
